{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPC2X_a9ErW7"
   },
   "source": [
    "# Getting Started with the Gemini API in Vertex AI with cURL\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_curl.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>       \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0cc0f48513b"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Eric Dong](https://github.com/gericdong), [Polong Lin](https://github.com/polong-lin) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axauUzNXEl_R"
   },
   "source": [
    "## Overview\n",
    "\n",
    "### Gemini\n",
    "Gemini is a family of generative AI models developed by Google DeepMind. Gemini models support prompts that include text, image, and video as input and support text responses as output.\n",
    "\n",
    "### Gemini API in Vertex AI\n",
    "\n",
    "The Gemini API in Vertex AI provides a unified interface for interacting with Gemini models. You can interact with the Gemini API by using the following methods:\n",
    "\n",
    "* Use [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) for quick testing and command generation.\n",
    "* Use cURL commands in Cloud Shell.\n",
    "* Use the Vertex AI SDK for Python in a Jupyter notebook\n",
    "\n",
    "This notebook focuses on using the **cURL commands** to call the Gemini API in Vertex AI.\n",
    "\n",
    "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyaOZAg_El_R"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you learn how to use the Gemini API in Vertex AI with cURL commands to interact with the Gemini 2.0 Flash (`gemini-2.0-flash-001`) model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Install the Python SDK.\n",
    "- Use the Gemini API in Vertex AI to interact with each model.\n",
    "  - Gemini 2.0 Flash (`gemini-2.0-flash-001`) model:\n",
    "    - Generate text from text prompts.\n",
    "    - Explore various features and configuration options.\n",
    "    - Generate text from image(s) and text prompts.\n",
    "    - Generate text from video.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJf9sLIIEl_S"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D50ekWXjEl_S"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n",
    "\n",
    "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ZGaZlxP9L0"
   },
   "source": [
    "### Set Google Cloud project\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8IivOG5SqY6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-west1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s84m7h6HSTR"
   },
   "source": [
    "### Defining environment variables for cURL commands\n",
    "\n",
    "These environment variables are used to construct the cURL commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "krJ8UOHKoPn3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"LOCATION\"] = LOCATION\n",
    "os.environ[\"API_ENDPOINT\"] = f\"{LOCATION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "854fbf388e2b"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7eeb063ac6d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_ID\"] = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZZUVBSzc0cR"
   },
   "source": [
    "### Generate content\n",
    "\n",
    "The generateContent method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. In this example, you send a text prompt using the `generateContent` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1979afec8834",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3129    0  3028  100   101   1219     40  0:00:02  0:00:02 --:--:--  1259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's a simplified explanation:\\n\\n1.  **Sunlight enters the Earth's atmosphere:** Sunlight is composed of all the colors of the rainbow.\\n\\n2.  **Sunlight collides with air molecules:** The Earth's atmosphere is primarily made up of nitrogen and oxygen molecules. When sunlight enters the atmosphere, it collides with these molecules.\\n\\n3.  **Scattering of light:** When sunlight collides with these molecules, the light is scattered in different directions.  This scattering is more effective at shorter wavelengths (blue and violet light) than at longer wavelengths (red and orange light).\\n\\n4.  **Blue light is scattered more:** Because blue and violet light have shorter wavelengths, they are scattered more strongly and in more directions than other colors. Think of it like this: the smaller waves of blue light are more easily \\\"bumped\\\" around by the air molecules.\\n\\n5.  **Why not violet then?** While violet light is scattered even *more* than blue, our eyes are less sensitive to violet.  Also, the sun emits slightly less violet light than blue light.  Therefore, the scattered light that we see is predominantly blue.\\n\\n**In summary:**  Blue light is scattered more effectively by the Earth's atmosphere than other colors, so we see the sky as blue when looking in directions away from the sun.\\n\\n**Important points to remember:**\\n\\n*   **Rayleigh scattering** is the key process.\\n*   **Wavelength matters:** Shorter wavelengths (blue, violet) are scattered more.\\n*   **Our eyes are less sensitive to violet:** This is why we perceive the sky as blue, not violet.\\n*   **Sunrise/Sunset:** At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. This means that most of the blue light is scattered away before it reaches us, leaving the longer wavelengths like orange and red to dominate. This is why sunsets are often red or orange.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"citationMetadata\": {\n",
      "        \"citations\": [\n",
      "          {\n",
      "            \"startIndex\": 1654,\n",
      "            \"endIndex\": 1779,\n",
      "            \"uri\": \"https://github.com/chethanhn29/Large_Language_Models-Pojects\"\n",
      "          },\n",
      "          {\n",
      "            \"startIndex\": 1727,\n",
      "            \"endIndex\": 1876\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"avgLogprobs\": -0.30721153678074659\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 6,\n",
      "    \"candidatesTokenCount\": 419,\n",
      "    \"totalTokenCount\": 425,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 6\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 419\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:09:50.612970Z\",\n",
      "  \"responseId\": \"zsoDaOq0Jf_TtOUP8KeAgQk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" }\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27701e417da6"
   },
   "source": [
    "### Streaming\n",
    "\n",
    "The Gemini API provides a streaming response mechanism. With this approach, you don't need to wait for the complete response; you can start processing fragments as soon as they're accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rzkCij_iS0we",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"It\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"'s tough to say definitively that Generative AI (GenAI) is \\\"best\\\" overall\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \", as its value depends heavily on the specific application and needs. However, it excels\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" in certain areas, which leads many to consider it superior in those contexts. Here's a breakdown of why GenAI is often considered the best choice for particular\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" tasks:\\n\\n**Strengths and Advantages of GenAI:**\\n\\n*   **Creative Content Generation:**\\n    *   **Text:** GenAI can create original stories,\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" poems, scripts, articles, summaries, and even different writing styles.\\n    *   **Images:** It can generate photorealistic images, artwork, and variations on existing images from textual descriptions (text-to-image).\\n    *\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"   **Audio:** GenAI can compose music, create sound effects, and even generate speech.\\n    *   **Video:** While still evolving, GenAI is increasingly capable of creating short video clips from text prompts.\\n*   **Automation\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" and Efficiency:**\\n    *   **Content Creation:** GenAI can automate the creation of large volumes of content, saving time and resources.\\n    *   **Code Generation:** It can assist in writing code, generating test cases, and even completing code snippets.\\n    *   **Data Augmentation:** GenAI\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" can create synthetic data to augment existing datasets, improving the performance of other AI models.\\n*   **Personalization and Customization:**\\n    *   **Personalized content:** GenAI can tailor content to individual user preferences, improving engagement and satisfaction.\\n    *   **Adaptive learning:** In education, GenAI\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" can create personalized learning experiences based on student needs.\\n*   **Problem Solving:**\\n    *   **Idea Generation:** GenAI can help brainstorm new ideas and solutions to complex problems.\\n    *   **Simulation:** It can simulate different scenarios to help businesses make better decisions.\\n    *   **Drug Discovery:** In the\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" pharmaceutical industry, GenAI is used to design new drug candidates.\\n*   **Accessibility and Scalability:**\\n    *   GenAI models are increasingly accessible through APIs and cloud platforms.\\n    *   It is possible to scale the use of GenAI without necessarily scaling human resources\\n\\n**Where GenAI Excels Compared\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" to Other Approaches:**\\n\\n*   **Traditional Rule-Based Systems:** GenAI can handle much more complex and nuanced tasks than rule-based systems, which rely on predefined rules. GenAI learns from data, enabling it to generalize and adapt to new situations.\\n*   **Traditional Machine Learning (ML):** While traditional\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" ML models excel at tasks like classification and prediction, GenAI stands out in generating novel and creative outputs.\\n*   **Human Creativity:** GenAI can be a powerful tool for augmenting human creativity, generating ideas, and assisting in the creative process.\\n\\n**Why It's NOT Always the \\\"Best\\\": Limitations and Considerations**\\n\\n\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"*   **Accuracy and Reliability:**\\n    *   **Hallucinations:** GenAI models can sometimes generate inaccurate or nonsensical information (often called \\\"hallucinations\\\").\\n    *   **Bias:** GenAI models can perpetuate biases present in the training data.\\n    *   **Lack of Understanding:** GenAI\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" does not truly \\\"understand\\\" the information it processes; it simply learns patterns in the data.\\n*   **Ethical Concerns:**\\n    *   **Misinformation:** GenAI can be used to create deepfakes and spread misinformation.\\n    *   **Copyright infringement:** Generating content that infringes on existing copyrights\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" is a risk.\\n    *   **Job displacement:** Concerns exist about the potential for GenAI to automate jobs currently performed by humans.\\n*   **Computational Cost:** Training and running large GenAI models can be computationally expensive.\\n*   **Data Dependency:** GenAI models require large amounts of high-quality\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" data to train effectively. If the training data is limited or biased, the model's performance will suffer.\\n*   **Lack of Human Oversight:** It is important to review the output of GenAI models, especially in high-stakes applications.\\n\\n**In summary:**\\n\\nGenAI is at its best when you\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" need to generate creative content, automate content creation, personalize experiences, or solve complex problems in innovative ways. However, it's crucial to be aware of its limitations, including potential inaccuracies, ethical concerns, and the need for human oversight.\\n\\nTo determine if GenAI is the \\\"best\\\" solution for a specific problem\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \", consider:\\n\\n*   **The specific task:** What exactly do you need to accomplish?\\n*   **The available data:** Do you have enough high-quality data to train a GenAI model?\\n*   **The desired level of accuracy and reliability:** How critical is it that the output is accurate?\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"\\n*   **The ethical considerations:** Are there any potential ethical risks associated with using GenAI for this task?\\n*   **The cost:** What is the cost of training and running a GenAI model compared to other solutions?\\n\\nBy carefully considering these factors, you can make an informed decision about whether GenAI is the right\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 13084    0 12982  100   102   2174     17  0:00:06  0:00:05  0:00:01  2160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            \"text\": \" tool for the job. In some cases, other AI techniques or even traditional methods might be more appropriate.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\"\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 6,\n",
      "    \"candidatesTokenCount\": 1063,\n",
      "    \"totalTokenCount\": 1069,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 6\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 1063\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:11:23.936237Z\",\n",
      "  \"responseId\": \"K8sDaK2SOYvKtOUPpbqe2AQ\"\n",
      "}\n",
      "]"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:streamGenerateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the GenAI best\" }\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e56BV7PH9t8"
   },
   "source": [
    "### Model parameters\n",
    "\n",
    "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Px8hSHhiH9t8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3360    0  2757  100   603   1049    229  0:00:02  0:00:02 --:--:--  1279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Here's a description of the image:\\n\\n**Overall Impression:**\\n\\nThe image shows a tabby cat standing in a snowy environment. The cat is the main subject and is in focus, while the background is a blur of white snow.\\n\\n**Cat Details:**\\n\\n*   **Coat:** The cat has a classic tabby pattern, with dark stripes on a lighter brown/gray background.\\n*   **Eyes:** The cat has yellow or golden eyes.\\n*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the camera with a curious or alert expression.\\n*   **Build:** The cat appears to be of average size and build.\\n\\n**Background:**\\n\\n*   The background is entirely snow-covered. There are some slight variations in texture, suggesting footprints or tire tracks in the snow.\\n*   The background is out of focus, which helps to emphasize the cat.\\n\\n**Overall Tone:**\\n\\nThe image has a natural and slightly cold feel due to the snow. The cat's expression adds a touch of curiosity and alertness.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"safetyRatings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 3.3950626e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.07694006\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 0.0003667287,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 4.4504002e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.052817475\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 8.659341e-06,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        }\n",
      "      ],\n",
      "      \"avgLogprobs\": -0.25366628425827353\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 261,\n",
      "    \"candidatesTokenCount\": 233,\n",
      "    \"totalTokenCount\": 494,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 3\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 233\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:12:46.821577Z\",\n",
      "  \"responseId\": \"fssDaMmSMv_TtOUP8KeAgQk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\"text\": \"Describe this image\"},\n",
    "        {\"file_data\": {\n",
    "          \"mime_type\": \"image/png\",\n",
    "          \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "        }}\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4-XhmPn_Pb-"
   },
   "source": [
    "### Chat\n",
    "\n",
    "The Gemini API supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions.\n",
    "\n",
    "Specify the `role` field only if the content represents a turn in a conversation. You can set `role` to one of the following values: `user`, `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YqSQSK-K-KVU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1767    0  1369  100   398   1217    354  0:00:01  0:00:01 --:--:--  1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Okay, let's get started. To best answer that, I need a little more context.  What kind of meeting is this? For example:\\n\\n*   **Is this a project kickoff meeting?** If so, the first order of business might be introductions and a review of the project goals.\\n*   **Is this a team meeting?** If so, it might be a review of action items from the previous meeting.\\n*   **Is this a brainstorming session?** If so, it might be a quick recap of the topic.\\n*   **Is this just a casual chat?**\\n\\nTell me more, and I can give you a specific answer. If you're unsure or just making it up, I can give you a common example like a team meeting.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.54026232760376725\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 21,\n",
      "    \"candidatesTokenCount\": 163,\n",
      "    \"totalTokenCount\": 184,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 21\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 163\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:13:39.790465Z\",\n",
      "  \"responseId\": \"s8sDaMGfMP_TtOUP8KeAgQk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello! I am glad you could both make it.\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"So what is the first order of business?\" }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f0f5fe3b331"
   },
   "source": [
    "### Function calling\n",
    "\n",
    "Function calling lets you create a description of a function in their code, then pass that description to a language model in a request. This sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as `find_movies` and `find_theaters`.\n",
    "\n",
    "Learn more about [function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "680b11b0ba4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3479    0   916  100  2563   1920   5373 --:--:-- --:--:-- --:--:--  7293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"functionCall\": {\n",
      "              \"name\": \"find_theaters\",\n",
      "              \"args\": {\n",
      "                \"movie\": \"Barbie\",\n",
      "                \"location\": \"Mountain View, CA\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.036088038574565544\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 191,\n",
      "    \"candidatesTokenCount\": 11,\n",
      "    \"totalTokenCount\": 202,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 191\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 11\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:15:08.533617Z\",\n",
      "  \"responseId\": \"DMwDaPHIIIvKtOUPpbqe2AQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"function_declarations\": [\n",
    "        {\n",
    "          \"name\": \"find_movies\",\n",
    "          \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"description\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"find_theaters\",\n",
    "          \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"get_showtimes\",\n",
    "          \"description\": \"Find the start times for movies playing in a specific theater\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              },\n",
    "              \"theater\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of theater\"\n",
    "              },\n",
    "              \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Date for requested showtime\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\",\n",
    "              \"movie\",\n",
    "              \"theater\",\n",
    "              \"date\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3g5n23lDtsN"
   },
   "source": [
    "## Multimodal input\n",
    "\n",
    "The Gemini 2.0 Flash  (`gemini-2.0-flash-001`) is a multimodal model that supports adding image and video in text or chat prompts for a text response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTfL2DDch4Lp"
   },
   "source": [
    "### Download an image from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KmtWSNLtJ7oD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg...\n",
      "/ [1 files][ 17.4 KiB/ 17.4 KiB]                                                \n",
      "Operation completed over 1 objects/17.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlyyaPgmhpyv"
   },
   "source": [
    "### Generate text from a local image\n",
    "\n",
    "Specify the [base64](https://en.wikipedia.org/wiki/Base64) encoding of the image or video to include inline in the prompt and the `mime_type` field. The supported [MIME types](https://en.wikipedia.org/wiki/Media_type) for images include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-uqZ-RWdtdit",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 24962    0   868  100 24094    893  24813 --:--:-- --:--:-- --:--:-- 25707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Yes, that is a cat in the picture. It appears to be a tabby cat.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.32958095952084188\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 263,\n",
      "    \"candidatesTokenCount\": 19,\n",
      "    \"totalTokenCount\": 282,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 5\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 19\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:16:52.392979Z\",\n",
      "  \"responseId\": \"dMwDaJP-F4vKtOUPpbqe2AQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Encode image data in base64\n",
    "# NOTE: This command only works on Linux.\n",
    "data=$(base64 -w 0 image.jpg)\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d \"{\n",
    "      'contents': {\n",
    "        'role': 'USER',\n",
    "        'parts': [\n",
    "          {\n",
    "            'text': 'Is it a cat?'\n",
    "          },\n",
    "          {\n",
    "            'inline_data': {\n",
    "              'data': '${data}',\n",
    "              'mime_type':'image/jpeg'\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "       }\n",
    "     }\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKr-BklmhjgP"
   },
   "source": [
    "### Generate text from an image on Google Cloud Storage\n",
    "\n",
    "Specify the Cloud Storage URI of the image to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported image MIME types include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "43pQE3_z3OjG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3504    0  2855  100   649   1389    315  0:00:02  0:00:02 --:--:--  1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Here's a description of the image:\\n\\n**Overall Impression:**\\n\\nThe image shows a tabby cat standing in a snowy environment. The cat is the main subject and is in focus, while the background is a blur of white snow.\\n\\n**Cat Details:**\\n\\n*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\\n*   **Eyes:** The cat has yellow or golden eyes.\\n*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the camera with a curious or alert expression.\\n*   **Build:** The cat appears to be of average build, not overly thin or overweight.\\n\\n**Background:**\\n\\n*   The background is entirely snow-covered. There are some subtle variations in the snow's texture, suggesting footprints or other disturbances.\\n*   The background is out of focus, which helps to emphasize the cat as the main subject.\\n\\n**Overall Tone:**\\n\\nThe image has a natural and slightly cold feel due to the snowy environment. The cat's alert expression adds a touch of curiosity and liveliness to the scene.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"safetyRatings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 3.004989e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.050032675\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 0.00029752046,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 3.293895e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.021136705\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 1.01153555e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        }\n",
      "      ],\n",
      "      \"avgLogprobs\": -0.24356434631347657\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 261,\n",
      "    \"candidatesTokenCount\": 250,\n",
      "    \"totalTokenCount\": 511,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 3\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 250\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-19T16:16:57.854288Z\",\n",
      "  \"responseId\": \"ecwDaJCSNIvKtOUPpbqe2AQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_ID=\"gemini-2.0-flash-001\"\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Describe this image\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"image/png\",\n",
    "            \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVF4vHuBOD8N"
   },
   "source": [
    "### Generate text from a video file\n",
    "\n",
    "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME types for video include `video/mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8kS5p0l_uHE"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d \\\n",
    "'{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted?Which city was this recorded in?Provide the answer JSON.\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"video/mp4\",\n",
    "            \"file_uri\": \"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_gemini_curl.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
